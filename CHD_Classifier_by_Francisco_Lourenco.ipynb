{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a98f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from models.detr import DETR\n",
    "from models.segmentation import DETRsegm\n",
    "from hubconf import detr_resnet101_panoptic, detr_resnet101\n",
    "from torchvision.transforms import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06863b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.hub.resnet import _resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7622b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DETRsegm_3D(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         detr = detr_resnet101_panoptic()\n",
    "#         conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc7d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_func(path):\n",
    "    path_id = int(path.split('/')[-1].split('_')[1])\n",
    "    return path_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a4badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_label(image, label):\n",
    "    fig, axs = plt.subplots(nrows=1,ncols=2, squeeze=False,figsize=(12, 12))\n",
    "    axs[0, 0].imshow(image)\n",
    "    axs[0, 0].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[], title='Image')\n",
    "    axs[0, 1].imshow(label)\n",
    "    axs[0, 1].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[], title='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9f6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetForSegmentation(Dataset):\n",
    "    \n",
    "    def __init__(self, image_paths, label_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image_np_array = nib.load(image_paths[i]).get_fdata()\n",
    "        image_torch_tensor = torch.from_numpy(image_np_array)\n",
    "        label_np_array = nib.load(image_paths[i]).get_fdata()\n",
    "        label_torch_tensor = torch.from_numpy(label_np_array)\n",
    "        return image_torch_tensor, label_np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06485547",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "864b4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/francisco/workspace/ImageCHD_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd529519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths = glob(f'{path}/*image.nii.gz',recursive=True)\n",
    "# label_paths = glob(f'{path}/*label.nii.gz',recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b202a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths.sort(key=sort_func)\n",
    "# label_paths.sort(key=sort_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76fc25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = DatasetForSegmentation(image_paths,label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f118759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpt, outp = dset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d8e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = _resnet();\n",
    "# model = model.half()\n",
    "# model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "914158a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inpt_right_shape = inpt.transpose(2,0).unsqueeze(0).unsqueeze(0).float()\n",
    "# new_size = [int(inpt_right_shape.shape[2]/3),int(inpt_right_shape.shape[3]/3),int(inpt_right_shape.shape[4]/3)]\n",
    "# inpt_resized = inpt_right_shape.resize_((1,1,new_size[0],new_size[1],new_size[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4afbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_3d = torch.nn.Conv3d(1,3,(1,3,3),padding = 1)\n",
    "# result = cv_3d(inpt_resized)\n",
    "# result_cuda = result.to(device)\n",
    "# result_2 = model(result_cuda.half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09bc8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detr = detr_resnet101_panoptic();\n",
    "# detr.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf70a2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da2874c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/anaconda3/envs/PyTorch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/francisco/anaconda3/envs/PyTorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "detr_seg = detr_resnet101_panoptic()\n",
    "detr_seg.eval();\n",
    "detr_seg.to(device);\n",
    "resnet_3d = _resnet();\n",
    "resnet_3d.to(device);\n",
    "detr_seg.detr.backbone[0] = resnet_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3190fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.ones((1, 1, 32, 64, 64),device=device)\n",
    "# im = torch.ones((1, 3, 128, 128),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c0ac49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/workspace/CHD_Classifier_by_Francisco_Lourenço/models/position_encoding.py:84: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 8, 16, 16])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mdetr_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/CHD_Classifier_by_Francisco_Lourenço/models/segmentation.py:59\u001b[0m, in \u001b[0;36mDETRsegm.forward\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     56\u001b[0m bbox_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_attention(hs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], memory, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(features[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m seg_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_head(src_proj, bbox_mask, [features[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mtensors, features[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtensors, features[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtensors])\n\u001b[1;32m     62\u001b[0m outputs_seg_masks \u001b[38;5;241m=\u001b[39m seg_masks\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetr\u001b[38;5;241m.\u001b[39mnum_queries, seg_masks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], seg_masks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py:1076\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1074\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1075\u001b[0m     )\n\u001b[0;32m-> 1076\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py:1121\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "preds = detr_seg(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a68688",
   "metadata": {},
   "source": [
    "3D: torch.Size([1, 2048, 8, 16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "595c4b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_logits': tensor([[[-0.1299,  0.9370, -0.2995,  ...,  0.4478,  0.8583, -0.3519],\n",
       "          [-0.1142,  0.9392, -0.2870,  ...,  0.4516,  0.8363, -0.3378],\n",
       "          [-0.1212,  0.9357, -0.3029,  ...,  0.4565,  0.8311, -0.3470],\n",
       "          ...,\n",
       "          [-0.1371,  0.9326, -0.2989,  ...,  0.4504,  0.8474, -0.3597],\n",
       "          [-0.1212,  0.9402, -0.2897,  ...,  0.4545,  0.8424, -0.3574],\n",
       "          [-0.1192,  0.9395, -0.2892,  ...,  0.4567,  0.8424, -0.3440]]],\n",
       "        device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " 'pred_boxes': tensor([[[0.4835, 0.5244, 0.4849, 0.4910, 0.4919, 0.4943],\n",
       "          [0.4834, 0.5252, 0.4848, 0.4908, 0.4921, 0.4940],\n",
       "          [0.4840, 0.5253, 0.4852, 0.4896, 0.4918, 0.4941],\n",
       "          [0.4837, 0.5247, 0.4850, 0.4907, 0.4918, 0.4941],\n",
       "          [0.4836, 0.5244, 0.4852, 0.4909, 0.4920, 0.4947],\n",
       "          [0.4836, 0.5252, 0.4845, 0.4899, 0.4919, 0.4937],\n",
       "          [0.4839, 0.5246, 0.4848, 0.4899, 0.4915, 0.4941],\n",
       "          [0.4837, 0.5243, 0.4842, 0.4899, 0.4916, 0.4943],\n",
       "          [0.4834, 0.5247, 0.4846, 0.4901, 0.4925, 0.4936],\n",
       "          [0.4840, 0.5240, 0.4846, 0.4898, 0.4926, 0.4942],\n",
       "          [0.4834, 0.5258, 0.4858, 0.4914, 0.4918, 0.4946],\n",
       "          [0.4835, 0.5239, 0.4839, 0.4910, 0.4928, 0.4941],\n",
       "          [0.4833, 0.5252, 0.4852, 0.4898, 0.4920, 0.4930],\n",
       "          [0.4832, 0.5244, 0.4847, 0.4911, 0.4921, 0.4939],\n",
       "          [0.4839, 0.5249, 0.4854, 0.4906, 0.4923, 0.4934],\n",
       "          [0.4832, 0.5242, 0.4841, 0.4912, 0.4914, 0.4943],\n",
       "          [0.4833, 0.5250, 0.4845, 0.4898, 0.4919, 0.4933],\n",
       "          [0.4834, 0.5247, 0.4852, 0.4902, 0.4916, 0.4940],\n",
       "          [0.4835, 0.5251, 0.4849, 0.4904, 0.4919, 0.4939],\n",
       "          [0.4833, 0.5252, 0.4850, 0.4897, 0.4921, 0.4935],\n",
       "          [0.4834, 0.5239, 0.4849, 0.4910, 0.4928, 0.4944],\n",
       "          [0.4837, 0.5243, 0.4847, 0.4910, 0.4920, 0.4941],\n",
       "          [0.4833, 0.5243, 0.4847, 0.4902, 0.4922, 0.4939],\n",
       "          [0.4837, 0.5249, 0.4849, 0.4904, 0.4915, 0.4943],\n",
       "          [0.4840, 0.5240, 0.4852, 0.4901, 0.4917, 0.4947],\n",
       "          [0.4832, 0.5249, 0.4847, 0.4909, 0.4919, 0.4941],\n",
       "          [0.4836, 0.5256, 0.4847, 0.4903, 0.4921, 0.4942],\n",
       "          [0.4830, 0.5250, 0.4850, 0.4902, 0.4920, 0.4938],\n",
       "          [0.4835, 0.5246, 0.4847, 0.4901, 0.4919, 0.4942],\n",
       "          [0.4832, 0.5247, 0.4845, 0.4907, 0.4921, 0.4942],\n",
       "          [0.4837, 0.5253, 0.4851, 0.4893, 0.4919, 0.4941],\n",
       "          [0.4837, 0.5250, 0.4847, 0.4903, 0.4921, 0.4942],\n",
       "          [0.4840, 0.5256, 0.4853, 0.4901, 0.4923, 0.4941],\n",
       "          [0.4836, 0.5255, 0.4856, 0.4898, 0.4917, 0.4937],\n",
       "          [0.4835, 0.5246, 0.4851, 0.4905, 0.4920, 0.4941],\n",
       "          [0.4832, 0.5246, 0.4848, 0.4904, 0.4917, 0.4937],\n",
       "          [0.4834, 0.5243, 0.4854, 0.4908, 0.4920, 0.4945],\n",
       "          [0.4836, 0.5248, 0.4848, 0.4912, 0.4924, 0.4940],\n",
       "          [0.4835, 0.5251, 0.4853, 0.4907, 0.4918, 0.4938],\n",
       "          [0.4836, 0.5243, 0.4845, 0.4903, 0.4923, 0.4940],\n",
       "          [0.4838, 0.5249, 0.4848, 0.4906, 0.4919, 0.4941],\n",
       "          [0.4835, 0.5243, 0.4845, 0.4906, 0.4924, 0.4942],\n",
       "          [0.4829, 0.5249, 0.4847, 0.4908, 0.4915, 0.4937],\n",
       "          [0.4835, 0.5246, 0.4851, 0.4903, 0.4919, 0.4941],\n",
       "          [0.4835, 0.5254, 0.4844, 0.4900, 0.4918, 0.4937],\n",
       "          [0.4835, 0.5241, 0.4844, 0.4905, 0.4919, 0.4938],\n",
       "          [0.4834, 0.5254, 0.4849, 0.4904, 0.4918, 0.4939],\n",
       "          [0.4838, 0.5251, 0.4853, 0.4912, 0.4923, 0.4940],\n",
       "          [0.4835, 0.5254, 0.4852, 0.4902, 0.4917, 0.4937],\n",
       "          [0.4834, 0.5250, 0.4853, 0.4906, 0.4916, 0.4937],\n",
       "          [0.4840, 0.5241, 0.4851, 0.4907, 0.4922, 0.4941],\n",
       "          [0.4835, 0.5250, 0.4847, 0.4907, 0.4923, 0.4938],\n",
       "          [0.4833, 0.5253, 0.4847, 0.4899, 0.4916, 0.4937],\n",
       "          [0.4831, 0.5243, 0.4847, 0.4912, 0.4926, 0.4939],\n",
       "          [0.4832, 0.5245, 0.4846, 0.4906, 0.4924, 0.4937],\n",
       "          [0.4840, 0.5248, 0.4851, 0.4903, 0.4914, 0.4947],\n",
       "          [0.4835, 0.5247, 0.4843, 0.4903, 0.4914, 0.4938],\n",
       "          [0.4837, 0.5247, 0.4844, 0.4904, 0.4927, 0.4939],\n",
       "          [0.4835, 0.5247, 0.4850, 0.4903, 0.4918, 0.4937],\n",
       "          [0.4831, 0.5248, 0.4851, 0.4902, 0.4918, 0.4937],\n",
       "          [0.4832, 0.5250, 0.4851, 0.4911, 0.4921, 0.4937],\n",
       "          [0.4836, 0.5241, 0.4846, 0.4900, 0.4921, 0.4941],\n",
       "          [0.4836, 0.5249, 0.4849, 0.4900, 0.4921, 0.4935],\n",
       "          [0.4834, 0.5250, 0.4846, 0.4900, 0.4924, 0.4934],\n",
       "          [0.4835, 0.5240, 0.4844, 0.4914, 0.4924, 0.4941],\n",
       "          [0.4835, 0.5247, 0.4848, 0.4904, 0.4924, 0.4935],\n",
       "          [0.4837, 0.5246, 0.4849, 0.4908, 0.4921, 0.4941],\n",
       "          [0.4834, 0.5255, 0.4850, 0.4901, 0.4921, 0.4936],\n",
       "          [0.4832, 0.5248, 0.4856, 0.4907, 0.4914, 0.4940],\n",
       "          [0.4838, 0.5244, 0.4847, 0.4903, 0.4919, 0.4939],\n",
       "          [0.4838, 0.5254, 0.4851, 0.4902, 0.4916, 0.4937],\n",
       "          [0.4839, 0.5253, 0.4855, 0.4906, 0.4920, 0.4935],\n",
       "          [0.4839, 0.5248, 0.4847, 0.4909, 0.4917, 0.4938],\n",
       "          [0.4834, 0.5243, 0.4848, 0.4901, 0.4924, 0.4940],\n",
       "          [0.4835, 0.5254, 0.4851, 0.4903, 0.4922, 0.4937],\n",
       "          [0.4840, 0.5244, 0.4846, 0.4905, 0.4919, 0.4942],\n",
       "          [0.4836, 0.5242, 0.4841, 0.4905, 0.4917, 0.4942],\n",
       "          [0.4834, 0.5240, 0.4851, 0.4915, 0.4921, 0.4935],\n",
       "          [0.4834, 0.5250, 0.4846, 0.4905, 0.4922, 0.4939],\n",
       "          [0.4836, 0.5245, 0.4850, 0.4906, 0.4924, 0.4941],\n",
       "          [0.4837, 0.5247, 0.4849, 0.4900, 0.4921, 0.4940],\n",
       "          [0.4841, 0.5249, 0.4850, 0.4899, 0.4922, 0.4937],\n",
       "          [0.4835, 0.5247, 0.4844, 0.4906, 0.4917, 0.4935],\n",
       "          [0.4834, 0.5254, 0.4854, 0.4900, 0.4917, 0.4941],\n",
       "          [0.4838, 0.5249, 0.4854, 0.4904, 0.4919, 0.4937],\n",
       "          [0.4835, 0.5241, 0.4849, 0.4908, 0.4925, 0.4943],\n",
       "          [0.4832, 0.5246, 0.4849, 0.4911, 0.4927, 0.4940],\n",
       "          [0.4834, 0.5241, 0.4848, 0.4913, 0.4920, 0.4938],\n",
       "          [0.4837, 0.5247, 0.4851, 0.4900, 0.4921, 0.4940],\n",
       "          [0.4834, 0.5248, 0.4855, 0.4902, 0.4916, 0.4942],\n",
       "          [0.4837, 0.5250, 0.4853, 0.4908, 0.4919, 0.4940],\n",
       "          [0.4839, 0.5250, 0.4851, 0.4897, 0.4920, 0.4939],\n",
       "          [0.4839, 0.5254, 0.4859, 0.4891, 0.4919, 0.4942],\n",
       "          [0.4835, 0.5244, 0.4850, 0.4905, 0.4925, 0.4937],\n",
       "          [0.4839, 0.5251, 0.4848, 0.4906, 0.4919, 0.4936],\n",
       "          [0.4834, 0.5245, 0.4855, 0.4908, 0.4922, 0.4940],\n",
       "          [0.4835, 0.5248, 0.4844, 0.4901, 0.4926, 0.4930],\n",
       "          [0.4838, 0.5250, 0.4851, 0.4906, 0.4921, 0.4942],\n",
       "          [0.4837, 0.5245, 0.4851, 0.4901, 0.4918, 0.4939],\n",
       "          [0.4834, 0.5245, 0.4845, 0.4905, 0.4923, 0.4937]]], device='cuda:0',\n",
       "        grad_fn=<SelectBackward0>)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8799028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 18]), torch.Size([1, 100, 6]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['pred_logits'].shape, preds['pred_boxes'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91380808",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db4f39",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6667fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The forward expects a NestedTensor, which consists of:\n",
    "       - samples.tensor: batched images, of shape [batch_size x 3 x H x W]\n",
    "       - samples.mask: a binary mask of shape [batch_size x H x W], containing 1 on padded pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216c643",
   "metadata": {},
   "source": [
    "torch.Size([1, 1, 32, 128, 128]) torch.Size([1, 32, 128, 128])\n",
    "\n",
    "torch.Size([1, 2048, 8, 32, 32]) torch.Size([1, 32, 128, 128])\n",
    "\n",
    "torch.Size([1, 2048, 4, 4]) torch.Size([1, 4, 4])\n",
    "\n",
    "\n",
    "torch.Size([1, 256, 4, 4])\n",
    "\n",
    "\n",
    "\n",
    "torch.Size([1, 2048, 8, 32, 32]) torch.Size([1, 32, 128, 128])\n",
    "\n",
    "\n",
    "torch.Size([1, 384, 32, 128, 128])\n",
    "\n",
    "torch.Size([1, 256, 8, 32, 32]) torch.Size([1, 32, 128, 128]) torch.Size([100, 256]) torch.Size([1, 256, 32, 128, 128])\n",
    "\n",
    "2D:\n",
    "\n",
    "torch.Size([1, 256, 4, 4]) torch.Size([1, 4, 4]) torch.Size([100, 256]) torch.Size([1, 256, 4, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
